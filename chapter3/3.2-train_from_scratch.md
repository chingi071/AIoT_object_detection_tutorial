# Transfer Learning vs Train from scratch

除了 Transfer Learning 之外，Train from scratch 也很常被提及。

Train from scratch 源自於 [Rethinking ImageNet Pre-training](https://arxiv.org/abs/1811.08883) 論文，表示不使用預訓練模型 (Pre-trained model)，而是直接進行訓練的方式。

論文中顯示了作者的多項實驗以及對 Transfer Learning 和 Train from scratch 的分析，並提出了三項觀點。

首先，使用 Transfer Learning 能夠比 Train from scratch 更快地收斂。但在資料量夠大的情況下，隨著訓練時間拉長，兩者的表現不相上下。

下圖為在 COCO dataset 中訓練所得到的 AP，其中 random init 是指參數隨機初始化 (random initialization)，表示 Train from scratch 方法；w/ pre-train 是指 with pre-training，表示 Transfer Learning 方法。從結果可看出 Train from scratch 需要迭代較多次才會收斂，然而訓練的表現不遜於使用 pre-trained model。

<div align=center><img width="600" height="500" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter3/pictures/006.jpg"/></div>


此外，作者在基於ResNet-50 FPN (R50 baseline，下圖1) 加入其他 trick 來比較。

* 第一個 trick (下圖2)：在訓練時加入 multi-scale augmentation (Training-time scale augmentation)

* 第二個 trick (下圖3)：使用 Cascade RCNN 且在訓練時加入 multi-scale augmentation

* 第三個 trick (下圖4)：於上一個 trick 中再加入測試時的 multi-scale augmentation (Test-time augmentation，TTA)

由結果可知，兩種方法在物件及分割的訓練成果差異不大，甚至 Train from scratch 可能會達到更好的結果。

<div align=center><img width="600" height="500" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter3/pictures/007.jpg"/></div>


第二，使用 pre-trained model 容易產生 over-fitting 的現象，泛化能力不如 Train from scratch 訓練的模型，當使用較少的資料集時，需要選擇合適的超參數來避免 over-fitting。

下圖皆是採用一部分的 COCO dataset 來訓練，左邊和中間的資料數量為 3500 張、右邊則是只有 1000 張。

左邊圖的模型使用原本預設的超參數，出現了 over-fitting 的狀況；中間圖的模型則修改了超參數，Transfer Learning 和 Train from scratch 的表現結果差不多；右邊圖的模型也使用修改後的超參數，但因為資料量較中間圖的小，因此 AP 較低。

![image](https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter3/pictures/008.jpg)


第三，當任務的目標對空間位置比較敏感，使用 ImageNet 的 pre-trained model 不見得會有好的效果。下圖是用於 keypoint 任務的結果，Train from scratch 比採用 ImageNet 的 pre-trained model 還快收斂。

<div align=center><img width="350" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter3/pictures/009.jpg"/></div>

## 使用時機

最後來說明 Transfer Learning 及 Train from scratch 的使用時機。

Transfer Learning 和 Train from scratch 的應用場景會根據目標任務的資料集大小、目標與源任務資料之間的相似性、有無訓練時間上的壓力以及運算資源是否有限等狀況區分。

由於 Train from scratch 需要較多迭代才能夠收斂至較好的結果，因此訓練時間上會比 Transfer Learning 要來得長，對於訓練時間與運算資源有限的狀況，使用 Transfer Learning 會更適合。

* 目標任務的資料集較小，且目標與源任務資料相近，可使用 Feature Extraction。也因為兩者資料集有高度相似性，使用 Fine-tuning 的話可能會導致 over-fitting。

* 目標任務的資料集較小，且目標與源任務資料差異較大，使用 Transfer Learning 或 Train from scratch 效果可能都不會很好，還是要盡可能地多蒐集一些資料，或者嘗試使用 Semi-supervised learning、Unsupervised learning 的方式來訓練。

* 目標任務的資料集大，且目標與源任務資料相近，可以使用 Fine-tuning 的方式。

* 目標任務的資料集大，且目標與源任務資料差異較大，可以直接使用 Train from scratch。

![image](https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter3/pictures/010.jpg)

