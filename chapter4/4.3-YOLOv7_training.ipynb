{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "ttg-GV7ZKFg_",
        "saI2JocATVbu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IvXFnmgyrmgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive"
      ],
      "metadata": {
        "id": "RZHa8LZIrmjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建模流程\n",
        "\n",
        "在這一小節中將會進行 YOLOv7 模型的訓練、預測並評估其表現結果。還沒看過 4.3-directions.md 的同學要先去看一下喔！\n",
        "\n",
        "第一步，先將 yolov7 github clone 至自己的資料路徑，並進入該資料夾中。\n"
      ],
      "metadata": {
        "id": "j-E0XDbW-zMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/WongKinYiu/yolov7"
      ],
      "metadata": {
        "id": "HL3Q6Ddw1Lio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7"
      ],
      "metadata": {
        "id": "wO8Ysjqp3Yx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "首先來看一下檔案內部結構\n",
        "\n",
        "* cfg：存放用於 training、deploy 或 baseline 的模型架構 yaml 檔案\n",
        "\n",
        "* data：存放用於訓練過程中的資料檔案 (coco.yaml) 及超參數設置檔 (hyp.scratch.xxx.yaml)\n",
        "\n",
        "* deploy/triton-inference-server：將 YOLOv7 模型部署至 NVIDIA 開源的 Inference Server\n",
        "\n",
        "* inference/images：存放可進行測試的圖片\n",
        "\n",
        "* models：存放模型架構的定義以及一些 NMS operation 操作\n",
        "\n",
        "* scripts：可藉由 get_coco.sh 檔案下載 COCO dataset\n",
        "\n",
        "* tools：存放 YOLOv7 在各種應用上的範例\n",
        "\n",
        "* utils：存放 dataloader、loss、activation function 等檔案，用於訓練或驗證階段\n",
        "\n",
        "* detect.py：用於進行推理運算預測\n",
        "\n",
        "* export.py：用於轉換模型\n",
        "\n",
        "* hubconf.py：用於支援 Pytorch Hub\n",
        "\n",
        "* test.py：用於計算評估指標\n",
        "\n",
        "* requirement.txt：訓練和測試過程中所需要的套件\n",
        "\n",
        "* train.py：用於訓練模型\n",
        "\n",
        "* train_aux.py：加入 auxiliary head 用於訓練模型\n"
      ],
      "metadata": {
        "id": "BMLCeGAj4jWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料前處理 (Data Preprocessing)"
      ],
      "metadata": {
        "id": "z3-6K2LmcJwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 載入資料集\n",
        "在進行訓練之前，要先準備資料集，這邊使用 [Kaggle Car Object Detection](https://www.kaggle.com/datasets/sshikamaru/car-object-detection/code)，總共有 1001 張 training 175 張 test data。\n",
        "\n",
        "我們使用 kaggle api 進行下載並解壓縮放入 data_file 資料夾中。"
      ],
      "metadata": {
        "id": "wj-LjcORdClH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "dJHXX0cKnfeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 這邊選擇剛下載的 kaggle.json\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "GUgzRbHmnir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "xsTYFJBVrGoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data_file"
      ],
      "metadata": {
        "id": "idSQ0Os530zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_save = os.path.join(os.getcwd(), 'data_file/')"
      ],
      "metadata": {
        "id": "MGthOYmtu_Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d sshikamaru/car-object-detection -p {data_save} --unzip"
      ],
      "metadata": {
        "id": "LXkY36ggszKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 檢查資料集\n",
        "\n",
        "在訓練模型之前，我們需要先對資料集進行檢查，以下分為幾個部分：\n",
        "\n",
        "* 資料集格式\n",
        "\n",
        "  - 檢查資料集格式是否為 YOLO 格式，若是其他格式要先將其進行轉換。\n",
        "\n",
        "* 資料集劃分\n",
        "\n",
        "  - 通常會將資料集劃分為訓練集 (training set)、驗證集 (validation set)、測試集 (test set)\n",
        "    - 訓練集 (training set)：用於訓練模型參數\n",
        "    - 驗證集 (validation set)：用於檢驗模型的訓練狀況，作為調整超參數的依據\n",
        "    - 測試集 (test set)：評估模型的表現結果\n",
        "\n",
        "* 資料集存放路徑\n",
        "\n",
        "  - YOLO 在訓練時，會從使用者建立的 train.txt 和 valid.txt 裡的路徑去尋找 training data 及 validation data (產生 train.txt、valid.txt 的步驟會在後續進行)。\n",
        "\n",
        "  - 需要注意的是，在 train.txt、valid.txt 中的資料路徑只需要填入資料集的圖片路徑，訓練時除了尋找資料集圖片，也會去尋找在同一個資料夾中同檔名的標記檔案 (txt 檔)。因此要將圖片和標記檔放在同一個資料夾中。\n"
      ],
      "metadata": {
        "id": "d9ivXNXM6M-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 觀察資料\n",
        "\n",
        "下載完 Kaggle Car Object Detection 資料集後，會看到以下檔案\n",
        "\n",
        "* training_images：用於訓練的資料集\n",
        "\n",
        "* testing_images：用於測試的資料集\n",
        "\n",
        "* train_solution_bounding_boxes (1).csv：訓練資料的 label\n",
        "\n",
        "* sample_submission.csv：用於上傳測試 label 的檔案\n",
        "\n",
        "首先來讀取訓練資料的路徑以及訓練資料的 label csv 檔，然後將物件框的資訊取出來，畫圖看看會呈現什麼樣子吧！"
      ],
      "metadata": {
        "id": "rwoqbKme6bh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOH6CTRm0b0h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = os.path.join(os.getcwd(), 'data_file/data/training_images')\n",
        "data_path = os.path.join(os.getcwd(), 'data_file/data/train_solution_bounding_boxes (1).csv')"
      ],
      "metadata": {
        "id": "aGMd-iVitJZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv(data_path)\n",
        "df_data"
      ],
      "metadata": {
        "id": "miwlIh0etJcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = df_data['image'][0]\n",
        "xmin = int(df_data['xmin'][0])\n",
        "ymin = int(df_data['ymin'][0])\n",
        "xmax = int(df_data['xmax'][0])\n",
        "ymax = int(df_data['ymax'][0])"
      ],
      "metadata": {
        "id": "KMzQDTUX61Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(images_path, image))\n",
        "cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255, 0, 255), 3)\n",
        "img_h, img_w, img_c = img.shape\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "p2WfUTVKzZy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 資料格式轉換\n",
        "\n",
        "由於資料集是使用 VOC xml 格式 (xmin, ymin, xmax, ymax)，因此需要先將其轉換成 YOLO 格式。\n",
        "\n",
        "在 4.1、4.2 節中有介紹格式轉換及實作，我們可以將程式碼包裝成一個函式進行使用。\n",
        "\n",
        "先來試試看轉換上一張圖片的格式吧！"
      ],
      "metadata": {
        "id": "_lo1_WU080uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo(img_w, img_h, xmin, ymin, xmax, ymax):\n",
        "  dw = 1./img_w\n",
        "  dh = 1./img_h\n",
        "  x_center = ((xmin + xmax) /2) * dw\n",
        "  y_center = ((ymin + ymax)/2) * dh\n",
        "  w_yolo = (xmax-xmin) * dw\n",
        "  h_yolo = (ymax-ymin) * dh\n",
        "\n",
        "  return x_center, y_center, w_yolo, h_yolo"
      ],
      "metadata": {
        "id": "cqrCvHAbzZ1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_center, y_center, w_yolo, h_yolo = convert_to_yolo(img_w, img_h, xmin, ymin, xmax, ymax)\n",
        "\n",
        "print(\"x_center:\", x_center)\n",
        "print(\"y_center:\", y_center)\n",
        "print(\"w_yolo:\", w_yolo)\n",
        "print(\"h_yolo:\", h_yolo)"
      ],
      "metadata": {
        "id": "JwhIX7EG1HN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 轉換全部檔案\n",
        "\n",
        "接著我們需要將全部檔案的格式都進行轉換後，寫成 txt 檔。\n",
        "\n",
        "要注意的是，在訓練 YOLO 模型時，默認會從資料集圖片路徑中尋找同檔名的標記檔案 (txt 檔)，因此要將圖片和標記檔放在同一個資料夾中。\n",
        "\n",
        "<img src=\"https://imgur.com/VuE8kbX.png\" width=200>\n"
      ],
      "metadata": {
        "id": "NeorL09-LoUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = os.path.join(os.getcwd(), 'data_file/train')\n",
        "valid_file = os.path.join(os.getcwd(), 'data_file/valid')\n",
        "\n",
        "if not os.path.exists(train_file):\n",
        "  os.makedirs(train_file)\n",
        "\n",
        "if not os.path.exists(valid_file):\n",
        "  os.makedirs(valid_file)"
      ],
      "metadata": {
        "id": "rvAQMJBH2taO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_box_txt(data, images_path, file):\n",
        "  org_image = ''\n",
        "  total_img_info = []\n",
        "  for i in range(len(data)):\n",
        "    img_info = []\n",
        "    image = data['image'][i]\n",
        "\n",
        "    if image != org_image and org_image != '' or i == len(data)-1:\n",
        "      image_name = org_image.split('.jpg')[0]\n",
        "      with open(os.path.join(file, image_name + '.txt'), 'w') as f:\n",
        "        for info in total_img_info:\n",
        "          f.write('\\n'.join(info))\n",
        "          f.write('\\r\\n')\n",
        "\n",
        "      total_img_info = []\n",
        "\n",
        "    img = cv2.imread(os.path.join(images_path, image))\n",
        "    img_h, img_w, img_c = img.shape\n",
        "    \n",
        "\n",
        "    source = os.path.join(images_path, image)\n",
        "    destination = os.path.join(file, image)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "    xmin = int(data['xmin'][i])\n",
        "    ymin = int(data['ymin'][i])\n",
        "    xmax = int(data['xmax'][i])\n",
        "    ymax = int(data['ymax'][i])\n",
        "\n",
        "    x_center, y_center, w_yolo, h_yolo = convert_to_yolo(img_w, img_h, xmin, ymin, xmax, ymax)\n",
        "    img_info.append(' '.join([str(0),str(x_center),str(y_center),str(w_yolo),str(h_yolo)]))\n",
        "\n",
        "    total_img_info.append(img_info)\n",
        "\n",
        "    org_image = image"
      ],
      "metadata": {
        "id": "RtMuqipwyj0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_box_txt(df_data, images_path, train_file)"
      ],
      "metadata": {
        "id": "bU-nm762xrpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 資料集劃分\n",
        "\n",
        "下一步，我們要來劃分資料集為訓練集 (training set)、驗證集 (validation set)、測試集 (test set)。由於 Kaggle Car Object Detection 資料集已經有區分測試集，因此我們只需要將剛剛轉換完的資料劃分成訓練集與驗證集。\n",
        "\n",
        "<img src=\"https://imgur.com/8Tl7N4i.png\" width=200>\n"
      ],
      "metadata": {
        "id": "ttg-GV7ZKFg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(train_file, valid_file):\n",
        "  source = os.listdir(train_file)[train_len:]\n",
        "\n",
        "  for i in source:\n",
        "    source = os.path.join(train_file, i)\n",
        "    shutil.move(source, valid_file)"
      ],
      "metadata": {
        "id": "uI9uzcvzIYDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = int(len(os.listdir(train_file))* 0.8)\n",
        "\n",
        "data_process(train_file, valid_file)"
      ],
      "metadata": {
        "id": "0nG54HY4Ik0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training data length:\", len(os.listdir(train_file)))\n",
        "print(\"validate data length:\", len(os.listdir(valid_file)))"
      ],
      "metadata": {
        "id": "Mq_vMSpv_lWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 train、valid txt 檔\n",
        "\n",
        "在這個步驟中，要把 train、valid 資料夾中的**圖片路徑**分別寫入 train.txt、valid.txt，訓練時會根據 txt 裡的路徑去尋找資料。\n",
        "\n",
        "<img src=\"https://imgur.com/Kb2FLcj.png\" width=700>\n"
      ],
      "metadata": {
        "id": "1PKX5z9mgtwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_txt_file(data_dir, save_file, txt_name):\n",
        "  data_list = []\n",
        "  for i in os.listdir(data_dir):\n",
        "    if i.endswith('.jpg'):\n",
        "      data_path = os.path.join(data_dir, i)\n",
        "      data_list.append(data_path)\n",
        "\n",
        "  with open(os.path.join(save_file, txt_name), 'a+') as f:\n",
        "    f.write('\\n'.join(data_list))"
      ],
      "metadata": {
        "id": "HJpA1GO477S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_file = os.path.join(os.getcwd(), 'data_file')\n",
        "\n",
        "write_txt_file(train_file, save_file, 'train.txt')\n",
        "write_txt_file(valid_file, save_file, 'valid.txt')"
      ],
      "metadata": {
        "id": "bop5j81gCJlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立自定義 yaml 檔\n",
        "\n",
        "模型在訓練時要讀取的 train、valid txt 檔路徑和總類別數量、類別名稱則會寫在 data 資料夾中的 yaml 檔裡，其中 train/ valid 檔案路徑可寫相對路徑或絕對路徑。\n",
        "\n",
        "<img src=\"https://imgur.com/xLGV6tF.png\" width=400>\n"
      ],
      "metadata": {
        "id": "-7ZD5FUtgx3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_file"
      ],
      "metadata": {
        "id": "pDgPH342DLz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_txt = os.path.join(save_file, 'train.txt')\n",
        "valid_txt = os.path.join(save_file, 'valid.txt')\n",
        "\n",
        "data_dict = {}\n",
        "data_dict['train'] = train_txt\n",
        "data_dict['val'] = valid_txt\n",
        "data_dict['nc'] = 1\n",
        "data_dict['names'] = ['Car']\n",
        "\n",
        "with open(os.path.join(os.getcwd(), 'data/car_data.yaml'), 'w') as f:\n",
        "  yaml.dump(data_dict, f)"
      ],
      "metadata": {
        "id": "cFB-o5rMLey7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 Config\n",
        "\n",
        "建立用於訓練的 Config 檔，這邊使用 yolov7-tiny，需修改第二行 nc 為目前訓練資料集的類別數量。\n",
        "\n",
        "由於 Kaggle Car Object Detection 資料集只有 1 個類別 ('Car')，因此將 nc 改成 1。其他參數也可以根據自己的需求去做更改。"
      ],
      "metadata": {
        "id": "FHncegZLgyyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "car_cfg = 'cfg/training/car_yolov7-tiny.yaml'\n",
        "! cp cfg/training/yolov7-tiny.yaml {car_cfg}\n",
        "! sed -i '2s/80/1/' {car_cfg}"
      ],
      "metadata": {
        "id": "p6I7YkBxDw7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型訓練 (Training)\n",
        "\n",
        "提供的超參數設定共有36種，以下介紹幾種常用的超參數\n",
        "\n",
        "* weights：初始化的模型權重，用於 Transfer Learning\n",
        "\n",
        "* cfg：模型架構 yaml 檔案\n",
        "\n",
        "* data：訓練資料檔案\n",
        "\n",
        "* hyp：超參數設置檔\n",
        "\n",
        "* epoch：訓練迭代次數\n",
        "\n",
        "* batch-size：批次大小\n",
        "\n",
        "* img-size：訓練圖片大小\n",
        "\n",
        "* rect：是否使用矩形大小的圖片，比如:512x288\n",
        "\n",
        "* resume：從上一次訓練迭代的地方開始繼續訓練\n",
        "\n",
        "* device：使用哪個 gpu 或 cpu\n",
        "\n",
        "* workers：使用多少進程數\n",
        "\n",
        "* project：訓練結果儲存路徑，默認為 'runs/train'\n",
        "\n",
        "* name：訓練結果儲存的資料夾名稱，默認為 'exp'\n",
        "\n",
        "* freeze：凍結哪幾層的網路層\n",
        "\n",
        "* v5-metric：是否使用 YOLOv5 新制定的 mAP 評估方式 (recall 最大值為 1)"
      ],
      "metadata": {
        "id": "bHTqO6eHMtTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train from scratch\n",
        "\n",
        "* 先來進行 Train from scratch，因此在初始化權重 weights 的部分設定為 ' '\n",
        "\n",
        "* cfg、data、hyp 路徑設定為剛剛建立的檔案\n",
        "\n",
        "* epoch 設定為 100、batch size 為 32、圖片大小使用 640x640\n",
        "\n",
        "* 由於 colab 只有一顆 gpu，因此將 device 設定為 0\n",
        "\n",
        "* 進程數設定為 1\n",
        "\n",
        "* 儲存模型的資料夾名稱設定為 yolov7-tiny，因此訓練好的模型會存在 runs/train/yolov7-tiny/weights 資料夾中"
      ],
      "metadata": {
        "id": "Dtp5_84MvMXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --weights '' --cfg cfg/training/car_yolov7-tiny.yaml --data data/car_data.yaml --hyp data/hyp.scratch.tiny.yaml --epochs 100 --batch-size 32 --img 640 640 --device 0 --workers 1 --name yolov7-tiny "
      ],
      "metadata": {
        "id": "_qOgv6XHIMfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(os.getcwd(), 'runs/train/yolov7-tiny/weights/best.pth')"
      ],
      "metadata": {
        "id": "TIUvYEneOxHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget {model_path} -O best.pth"
      ],
      "metadata": {
        "id": "h-bXGcw4Nyuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning\n",
        "\n",
        "* 接著來使用 Transfer Learning 方法，初始化權重 weights 使用 'yolov7_training.pt'\n",
        "\n",
        "* cfg、data、hyp 路徑設定為剛剛建立的檔案\n",
        "\n",
        "* epoch 設定為 100、batch size 為 32、圖片大小使用 640x640\n",
        "\n",
        "* 由於 colab 只有一顆 gpu，因此將 device 設定為 0\n",
        "\n",
        "* 進程數設定為 1\n",
        "\n",
        "* 訓練結果的儲存路徑更改為 runs/transfer_learning\n",
        "\n",
        "* 儲存模型的資料夾名稱設定為 yolov7-tiny，因此訓練好的模型會存在 runs/transfer_learning/yolov7-tiny/weights 資料夾中"
      ],
      "metadata": {
        "id": "saI2JocATVbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ],
      "metadata": {
        "id": "E_0uq1xaZggL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --weights 'yolov7_training.pt' --cfg cfg/training/car_yolov7-tiny.yaml --data data/car_data.yaml --hyp data/hyp.scratch.tiny.yaml --epochs 100 --batch-size 32 --img 640 640 --device 0 --workers 1 --project runs/transfer_learning --name yolov7-tiny \n"
      ],
      "metadata": {
        "id": "SDCfolm0O95J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型預測 (Predict)\n",
        "\n",
        "提供的超參數設定共有18種，以下介紹幾種常用的超參數\n",
        "\n",
        "* weights：要使用的模型權重\n",
        "\n",
        "* source：要預測的檔案，可以設定為圖片、資料夾路徑或是攝影鏡頭 (設定為0)\n",
        "\n",
        "* img-size：訓練圖片大小\n",
        "\n",
        "* conf-thres：object 信心程度的 threshold，默認為 0.25\n",
        "\n",
        "* iou-thres：用於 NMS 的 IoU threshold，默認為 0.45\n",
        "\n",
        "* device：使用哪個 gpu 或 cpu\n",
        "\n",
        "* view-img：是否要顯示畫面\n",
        "\n",
        "* save-txt；是否要將預測結果儲存至 txt 檔\n",
        "\n",
        "* save-conf：是否要將預測結果的信心程度儲存至 txt 檔\n",
        "\n",
        "* project：預測結果儲存路徑，默認為 'runs/detect'\n",
        "\n",
        "* name：預測結果儲存的資料夾名稱，默認為 'exp'"
      ],
      "metadata": {
        "id": "LqDXDuX5TzGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train from scratch\n",
        "\n",
        "* 接著使用 Train from scratch 所訓練的模型，我們訓練模型儲存路徑在 runs/train/yolov7-tiny/，因此權重設定為在這個路徑下的 weights/best.pt\n",
        "\n",
        "* 預測圖片選擇在 data_file/test/images/ 路徑下的其中一張圖片\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M1nDkAmdwi5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python detect.py --weights runs/train/yolov7-tiny/weights/best.pt --source data_file/data/testing_images/vid_5_31560.jpg --project runs/detect"
      ],
      "metadata": {
        "id": "TzEaEqt5YBY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open(os.path.join(os.getcwd(), 'runs/detect/exp/vid_5_31560.jpg'))"
      ],
      "metadata": {
        "id": "VVglsRKHrSBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning\n",
        "\n",
        "* 接著使用 Transfer Learning 所訓練的模型，我們訓練模型儲存路徑在 runs/transfer_learning/yolov7-tiny/，因此權重設定為在這個路徑下的 weights/best.pt\n",
        "\n",
        "* 預測圖片選擇在 data_file/test/images/ 路徑下的其中一張圖片\n",
        "\n",
        "* 儲存預測結果的路徑設定為 runs/transfer_learning_detect/"
      ],
      "metadata": {
        "id": "wbHEf2N3UOg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python detect.py --weights runs/transfer_learning/yolov7-tiny/weights/best.pt --source data_file/data/testing_images/vid_5_31560.jpg --project runs/transfer_learning_detect"
      ],
      "metadata": {
        "id": "hodMyZdoUHXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open(os.path.join(os.getcwd(), 'runs/transfer_learning_detect/exp/vid_5_31560.jpg'))"
      ],
      "metadata": {
        "id": "of_lLqjWrROo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型評估 (Evaluation)\n",
        "\n",
        "最後來評估模型的 performance\n",
        "\n",
        "提供的超參數設定共有20種，以下介紹幾種常用的超參數\n",
        "\n",
        "* weights：要進行評估的模型權重\n",
        "\n",
        "* data：用於評估的資料檔案\n",
        "\n",
        "* conf-thres：object 信心程度的 threshold，默認為 0.25\n",
        "\n",
        "* iou-thres：用於 NMS 的 IoU threshold，默認為 0.45\n",
        "\n",
        "* task：要使用於 train、validate、test\n",
        "\n",
        "\n",
        "\n",
        "* project：訓練結果儲存路徑，默認為 'runs/train'\n",
        "\n",
        "* name：訓練結果儲存的資料夾名稱，默認為 'exp'\n",
        "\n",
        "* v5-metric：是否使用 YOLOv5 新制定的 mAP 評估方式 (recall 最大值為 1)"
      ],
      "metadata": {
        "id": "NYDERek4EDKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train from scratch\n",
        "\n",
        "使用 Train from scratch 所訓練的模型，我們訓練模型儲存路徑在 runs/train/yolov7-tiny/，因此權重設定為在這個路徑下的 weights/best.pt\n"
      ],
      "metadata": {
        "id": "oP6MrUblTWDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python test.py --weights runs/train/yolov7-tiny/weights/best.pt --data data/car_data.yaml --conf 0.001 --iou 0.65 --img 640 --batch 32 --device 0 --name yolov7-tiny"
      ],
      "metadata": {
        "id": "KgGv7FinEE39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning\n",
        "\n",
        "使用 Transfer Learning 所訓練的模型，我們訓練模型儲存路徑在 runs/transfer_learning/yolov7-tiny/，因此權重設定為在這個路徑下的 weights/best.pt"
      ],
      "metadata": {
        "id": "SiUoMP9qTWud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python test.py --weights runs/transfer_learning/yolov7-tiny/weights/best.pt --data data/car_data.yaml --conf 0.001 --iou 0.65 --img 640 --batch 32 --device 0 --name yolov7-tiny"
      ],
      "metadata": {
        "id": "_wo26npHgz_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}