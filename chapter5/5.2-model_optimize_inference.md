# 模型優化與推論
NVIDIA 為了加速深度學習模型執行效率而開發了 TensorRT library，能夠在 GPU 上實現低延遲、高吞吐量的部屬。
基於 TensorRT 的推論運行速度會比僅使用 CPU 快40倍，提供精度 INT8 和 FP16 優化，支援 TensorFlow、Caffe、Mxnet、Pytorch 等深度學習框架，其中 Mxnet、Pytorch 需先轉換為 ONNX 格式。

<div align=center><img width="800" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/022.jpg"/></div>


## 遠端傳輸模型

設置完 Jetson nano 環境後，要來將第四章實際演練中訓練好的模型佈署至 Jetson nano，需要先把模型和一些檔案遠端傳輸給 Jetson nano。在 Windows 和 Linux 之間傳輸檔案時，需要透過 SFTP (Secure File Transfer Protocol) 或 SCP (Secure Copy Protocol) 來進行。

我的本地端電腦的作業系統是使用 Windows，可藉由 MobaXterm、WinSCP、PuTTY、FileZilla 等伺服器軟體連線至 Jetson nano 並傳輸檔案。

這邊我使用 MobaXterm 來進行操作，MobaXterm 是一套 Windows SSH Client 軟體，使用方式非常便利直覺，能夠直接操作滑鼠拖曳或下載檔案，安裝連結：https://mobaxterm.mobatek.net/download.html

安裝好後打開 MobaXterm 會呈現以下畫面，點選左上角的 Session

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/015.jpg"/></div>


選擇 SFTP，並輸入 Jetson nano ip 地址及使用者名稱

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/016.jpg"/></div>


建立新資料夾，待會要傳送的檔案會放在這個資料夾中

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/017.jpg"/></div>


接著將訓練好的模型用滑鼠拖曳至剛建立好的新資料夾

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/018.jpg"/></div>

也放入 yolov7_car.zip 檔案

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/019.jpg"/></div>


再將剛剛傳輸的檔案解壓縮後，放入模型。

```
$ cd AIoT_OD/
$ unzip yolov7_car.zip
$ mv best.pt yolov7_car
```

若是想使用 terminal 操作，可以點選左上角的 Session -> SSH，並輸入 Jetson nano ip 地址及使用者名稱

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/020.jpg"/></div>

就可以使用右邊的 terminal 進行操作

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/021.jpg"/></div>

如果作業系統是使用 MAC 或 Linux，可以直接使用 scp 來遠端傳輸檔案。

先安裝 openssh-server 以支援 SSH server的功能。

```
$ sudo apt install openssh-server
```

從本地端傳輸檔案至 Jetson nano，指令為 scp -r 要傳送的檔案路徑 使用者名稱@ Jetson nano IP: 遠端路徑

```
# 建立資料夾並傳輸檔案
$ mkdir AIoT_OD
$ scp -r best.pt chingi@192.168.0.12: /home/chingi/AIoT_OD/
$ scp -r yolov7_car.zip chingi@192.168.0.12: /home/chingi/AIoT_OD/
```

## 安裝所需 library

下一步，要來安裝優化模型過程中所需要的 library，這邊安裝需要花費一些時間。

* 安裝 torch，使用 1.9 版本

其他版本可以參考：https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048

```
$ wget https://nvidia.box.com/shared/static/h1z9sw4bb1ybi0rm3tu8qdj8hs05ljbm.whl -O  torch-1.9.0-cp36-cp36m-linux_aarch64.whl
$ sudo apt-get install python3-pip libopenblas-base libopenmpi-dev libomp-dev -y
$ pip3 install Cython
$ pip3 install numpy torch-1.9.0-cp36-cp36m-linux_aarch64.whl
```

* 安裝 torchvision，使用 0.10 版本

```
$ sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libavcodec-dev libavformat-dev libswscale-dev -y
$ pip3 install Pillow==8.4

$ git clone --branch release/0.10 https://github.com/pytorch/vision torchvision   
$ cd torchvision
$ export BUILD_VERSION=0.10
$ python3 setup.py install --user
```

* 安裝 onnx 及其他需要的 library

```
$ sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran qtbase5-dev python3-matplotlib
$ pip3 install pycuda
$ pip3 install tqdm seaborn
$ cd ..
$ wget https://raw.githubusercontent.com/jkjung-avt/jetson_nano/master/install_protobuf-3.8.0.sh
$ bash install_protobuf-3.8.0.sh
$ pip3 install onnx
```

* 確認是否安裝成功

```
$ python3
>> import torch
>> import torchvision
>> import onnx 
```

## 優化模型

終於要來對模型做優化啦～

由於要將模型轉為 ONNX 後，才能再轉換為 TensorRT，因此先來進行 ONNX 的轉換。

執行以下指令進行轉換，轉換完後會儲存在 yolov7_car 資料夾中。

```
$ cd yolov7_car
$ python3 export.py --weights best.pt --grid --end2end --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640
$ mv best.onnx best_for_trt.onnx
```

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/023.jpg"/></div>


接著將模型轉換為 TensorRT

```
$ cd ..
$ git clone https://github.com/Linaom1214/tensorrt-python.git
$ cd tensorrt-python
$ python3 export.py -o ../yolov7_car/best_for_trt.onnx -e ../yolov7_car/best.trt -p fp16
```

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/024.jpg"/></div>


## 模型推論

### TensorRT inference

轉換完模型後，就可以進行推理運算囉～

進入至 yolov7_car 資料夾中，並執行 TensorRT 的推理運算

```
$ cd ../yolov7_car
$ python3 trt_inference.py --weights best.trt --source-path vid_5_31560.jpg --save-file save_trt
```

由於  TensorRT 版本在 8.2 時，信心程度的輸出會有問題，要升級至 8.4 版本才會正常。但Jetson nano 的 TensorRT 版本目前只有支援到 8.2，若是使用 Jetson AGX Orin、Jetson Xavier NX、Jetson AGX Xavier 等系列的邊緣機器就可以使用 8.4 版本的 TensorRT。
可參考：https://github.com/WongKinYiu/yolov7/issues/598

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/trt_output.jpg"/></div>

### Torch inference

接著，來試著使用原本模型進行推理運算吧!
```
$ python3 detect.py --weights best.pt --source vid_5_31560.jpg --project save
```

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/output.jpg"/></div>

### ONNX inference

最後，來試試看使用 ONNX model，依照以下指令來安裝 onnxruntime，若需要安裝其他版本可參考：https://elinux.org/Jetson_Zoo#ONNX_Runtime

```
$ wget https://nvidia.box.com/shared/static/pmsqsiaw4pg9qrbeckcbymho6c01jj4z.whl -O onnxruntime_gpu-1.11.0-cp36-cp36m-linux_aarch64.whl
$ pip3 install onnxruntime_gpu-1.11.0-cp36-cp36m-linux_aarch64.whl
```

安裝完後要再重新轉換模型～雖然在上一個 part 已經轉換過 ONNX 了， 但直接運行會有問題，需要再加上 ```--max-wh 640```

```
$ python3 export.py --weights best.pt --grid --end2end --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --max-wh 640
$ python3 onnx_inference.py --weights best.onnx --source-path vid_5_31560.jpg --save-file save_onnx
```

<div align=center><img width="600" height="400" src="https://github.com/chingi071/AIoT_object_detection_tutorial/blob/main/chapter5/pictures/onnx_output.jpg"/></div>
